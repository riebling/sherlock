import django
import logging
import sys
from tkinter import *

import scrapy
from twisted.internet import reactor
from scrapy.crawler import CrawlerProcess, CrawlerRunner
from scrapy.http.request import Request
from twisted.application.reactors import Reactor

print("The location of Scrapy is:")
print (scrapy.__file__)


# S C R A P Y    S T U F F
#
logging.getLogger('myScrapy').setLevel(logging.WARNING)
runner = CrawlerRunner({
    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'
})
 

# Tk stuff: Python native GUI

 
def callback_quit():
    print("quit button pressed")
    sys.exit()

root = Tk()
root.wm_title("Scrapy Demo")


def callback_scrape():
    theUrl = chosenUrl.get()
    print("theUrl:"+theUrl)
    chosenUrl.set(theUrl)
    
    deferredCallback = runner.crawl(ScrapeSpider)
    deferredCallback.addBoth(lambda _: Reactor.stop())
    Reactor.run()



#b2 = Button(root, text="Scrape Quotes", command=callback_quotes)
#b2.pack()
urls = ("Choose URL to Scrape",
    "http://speechkitchen.org/category/whats-cooking",
    "http://quotes.toscrape.com/tag/humor/")

chosenUrl = StringVar(root)
chosenUrl.set(urls[0])
e = OptionMenu(root, chosenUrl, *urls)


e.grid(row=0,column=0)


b3 = Button(root, text="Quit", command=callback_quit)
b3.grid(row=0,column=1)

lab = Label(root, textvariable=chosenUrl)
lab.grid(row=1)

b = Button(root, text="Scrape", command=callback_scrape)
b.grid(row=2,column=1)

tex = Text()
tex.grid(row=2,column=0)


class ScrapeSpider(scrapy.Spider):
    name = 'scrapespider'

    start_urls = ['']
    
    def start_requests(self):
        theUrl = chosenUrl.get()
        print("spider Url: "+theUrl)
        yield Request(theUrl, self.parse)
                  
 
    def parse(self, response):
        for title in response.css('h1.entry-title'):
            print (title.css('a ::text').extract_first())
            tex.insert(END, title.css('a ::text').extract_first())
            tex.see(END)
            yield {'title': title.css('a ::text').extract_first()}
 
        for quote in response.css('div.quote'):
            print (quote.css('span.text::text').extract_first())
            print (quote.xpath('span/small/text()').extract_first())
            tex.insert(END, quote.css('span.text::text').extract_first() + "\n")
            tex.insert(END, quote.xpath('span/small/text()').extract_first() + "\n\n")
            tex.see(END)
            
            yield {
                'text': quote.css('span.text::text').extract_first(),
                'author': quote.xpath('span/small/text()').extract_first(),
                }
 
        #next_page = response.css('div.prev-post > a ::attr(href)').extract_first()
        #if next_page:
        #    yield myScrapy.Request(response.urljoin(next_page), callback=self.parse)
 
# class QuotesSpider(scrapy.Spider):
#     name = "quotes"
#     start_urls = [
#         'http://quotes.toscrape.com/tag/humor/',
#         ]
#  
#     def parse(self, response):
#         for quote in response.css('div.quote'):
#             print (quote.css('span.text::text').extract_first())
#             print (quote.xpath('span/small/text()').extract_first())
#             yield {
#                 'text': quote.css('span.text::text').extract_first(),
#                 'author': quote.xpath('span/small/text()').extract_first(),
#                 }
#  
#             next_page = response.css('li.next a::attr("href")').extract_first()
#             if next_page is not None:
#                 next_page = response.urljoin(next_page)
#                 yield scrapy.Request(next_page, callback=self.parse)
 

 

 

mainloop()
#root.mainloop()
